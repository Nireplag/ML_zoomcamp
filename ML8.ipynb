{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWtmrh2xuqXz1YAIATZrev",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nireplag/ML_zoomcamp/blob/main/ML8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "File handling to improve notebook memory consumption"
      ],
      "metadata": {
        "id": "D6N6RbHFbFNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clear already downloaded files\n",
        "!rm -rf data\n",
        "!rm -rf data.zip"
      ],
      "metadata": {
        "id": "z6_ECpW5aZbt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V1GQWuKYgOk",
        "outputId": "3603b4d6-7e15-4e45-f17b-213a8d3ff7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-15 19:47:13--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/405934815/e6c56cb7-dce1-463f-865b-01e913c38485?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231115%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231115T194713Z&X-Amz-Expires=300&X-Amz-Signature=942d4b3ca09240c4bff0b227d77e15bac2c1441c160e24a891cd910ce3b3fab7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=405934815&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-11-15 19:47:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/405934815/e6c56cb7-dce1-463f-865b-01e913c38485?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231115%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231115T194713Z&X-Amz-Expires=300&X-Amz-Signature=942d4b3ca09240c4bff0b227d77e15bac2c1441c160e24a891cd910ce3b3fab7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=405934815&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 117446836 (112M) [application/octet-stream]\n",
            "Saving to: ‘./data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 112.01M   276MB/s    in 0.4s    \n",
            "\n",
            "2023-11-15 19:47:14 (276 MB/s) - ‘./data.zip’ saved [117446836/117446836]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download file\n",
        "!wget -P ./ https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
        "!unzip data.zip &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove zip file\n",
        "!rm -rf data.zip"
      ],
      "metadata": {
        "id": "Wpn_yu-SaJlp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define input paramenters for CNN"
      ],
      "metadata": {
        "id": "EeZEyYe3bTUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FeMGYt57ckfH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (150,150,3)\n",
        "filters = 32\n",
        "kernel_size = (3,3)\n",
        "activation_mode = 'relu'\n",
        "pooling_size = (2,2)\n",
        "dense1 = 64\n",
        "dense2 = 1\n",
        "dense2_activation = 'sigmoid'"
      ],
      "metadata": {
        "id": "bq-Jvm21bkaF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creation of model\n",
        "\n",
        "input = tf.keras.Input(shape = input_shape)\n",
        "cnn = tf.keras.layers.Conv2D(filters,\n",
        "                             kernel_size,\n",
        "                             activation=activation_mode)(input)\n",
        "pooling = tf.keras.layers.MaxPooling2D(pool_size = pooling_size)(cnn)\n",
        "flat = tf.keras.layers.Flatten()(pooling)\n",
        "inner = tf.keras.layers.Dense(dense1, activation = activation_mode)(flat)\n",
        "output = tf.keras.layers.Dense(dense2, activation = dense2_activation)(inner)\n",
        "\n",
        "model = tf.keras.Model(input, output)"
      ],
      "metadata": {
        "id": "_WL_Yx9Kcs0R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compilation of model\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
        "loss = tf.keras.losses.BinaryCrossentropy() # this one is the best approach for binary categorization problems\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "kXLHINUzhae3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of parameters inside CNN -> 896\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woPpjPS4jPrt",
        "outputId": "542e2928-a813-4725-d806-033830e16451"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 175232)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                11214912  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11215873 (42.79 MB)\n",
            "Trainable params: 11215873 (42.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image generator with normalization\n",
        "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_ds = train_gen.flow_from_directory(\n",
        "    '/content/data/train',\n",
        "    batch_size=20,\n",
        "    target_size=(150, 150),\n",
        "    shuffle = True,\n",
        "    class_mode = 'binary')\n",
        "\n",
        "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_ds = test_gen.flow_from_directory(\n",
        "    '/content/data/test',\n",
        "    batch_size=20,\n",
        "    target_size=(150, 150),\n",
        "    shuffle = True,\n",
        "    class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOpZveGkkCTB",
        "outputId": "60c87f6f-b6b1-46ad-c521-98b5d76fb08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3677 images belonging to 2 classes.\n",
            "Found 918 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o59-PYellqae",
        "outputId": "9a25c9ba-b968-4317-dada-21e650cc19df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bee': 0, 'wasp': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKuvyC-glyHW",
        "outputId": "92d9504a-864f-476a-beca-7291a9d189f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bee': 0, 'wasp': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds,\n",
        "                    epochs = 10,\n",
        "                    validation_data = test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRLDdtriqKl8",
        "outputId": "a17ea6c5-12db-4268-f145-5d518acd3352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "184/184 [==============================] - 10s 52ms/step - loss: 0.6932 - accuracy: 0.5377 - val_loss: 0.6836 - val_accuracy: 0.5359\n",
            "Epoch 2/10\n",
            "184/184 [==============================] - 8s 41ms/step - loss: 0.6805 - accuracy: 0.5488 - val_loss: 0.6711 - val_accuracy: 0.5577\n",
            "Epoch 3/10\n",
            "184/184 [==============================] - 8s 45ms/step - loss: 0.6683 - accuracy: 0.5668 - val_loss: 0.6504 - val_accuracy: 0.6057\n",
            "Epoch 4/10\n",
            "184/184 [==============================] - 7s 38ms/step - loss: 0.6591 - accuracy: 0.5937 - val_loss: 0.6352 - val_accuracy: 0.6068\n",
            "Epoch 5/10\n",
            "184/184 [==============================] - 9s 46ms/step - loss: 0.6342 - accuracy: 0.6348 - val_loss: 0.6878 - val_accuracy: 0.5632\n",
            "Epoch 6/10\n",
            "184/184 [==============================] - 8s 42ms/step - loss: 0.6073 - accuracy: 0.6562 - val_loss: 0.5970 - val_accuracy: 0.6906\n",
            "Epoch 7/10\n",
            "184/184 [==============================] - 7s 38ms/step - loss: 0.5815 - accuracy: 0.6968 - val_loss: 0.5829 - val_accuracy: 0.6885\n",
            "Epoch 8/10\n",
            "184/184 [==============================] - 7s 40ms/step - loss: 0.5384 - accuracy: 0.7313 - val_loss: 0.5573 - val_accuracy: 0.7200\n",
            "Epoch 9/10\n",
            "184/184 [==============================] - 8s 46ms/step - loss: 0.5130 - accuracy: 0.7528 - val_loss: 0.5260 - val_accuracy: 0.7495\n",
            "Epoch 10/10\n",
            "184/184 [==============================] - 7s 37ms/step - loss: 0.4943 - accuracy: 0.7713 - val_loss: 0.5900 - val_accuracy: 0.6917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# median of training accuracy\n",
        "np.median(history.history['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfj1btHN0wFh",
        "outputId": "c39311ff-f97d-4179-dad6-1d611f3d8a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.645499050617218"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# standard deviation of training losses\n",
        "np.std(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhJqxTUY1PLw",
        "outputId": "c03b6635-cd01-44f0-a5d5-519c4c263967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06851583774543082"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                            rotation_range=50,\n",
        "                                                            width_shift_range=0.1,\n",
        "                                                            height_shift_range=0.1,\n",
        "                                                            zoom_range=0.1,\n",
        "                                                            horizontal_flip=True,\n",
        "                                                            fill_mode='nearest')\n",
        "\n",
        "train_ds = train_gen.flow_from_directory(\n",
        "    '/content/data/train',\n",
        "    batch_size=20,\n",
        "    target_size=(150, 150),\n",
        "    shuffle = True,\n",
        "    class_mode = 'binary')\n",
        "\n",
        "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                            rotation_range=50,\n",
        "                                                            width_shift_range=0.1,\n",
        "                                                            height_shift_range=0.1,\n",
        "                                                            zoom_range=0.1,\n",
        "                                                            horizontal_flip=True,\n",
        "                                                            fill_mode='nearest')\n",
        "test_ds = test_gen.flow_from_directory(\n",
        "    '/content/data/test',\n",
        "    batch_size=20,\n",
        "    target_size=(150, 150),\n",
        "    shuffle = True,\n",
        "    class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_qF0tf9hd7v",
        "outputId": "7aff16dc-4e02-48be-e9b0-7030ac052858"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3677 images belonging to 2 classes.\n",
            "Found 918 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds,\n",
        "                    epochs = 10,\n",
        "                    validation_data = test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c2i05yFiXkr",
        "outputId": "fcf2e143-71cf-47a2-f5b7-56e1edc95572"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "184/184 [==============================] - 32s 176ms/step - loss: 0.5075 - accuracy: 0.7639 - val_loss: 0.5062 - val_accuracy: 0.7800\n",
            "Epoch 2/10\n",
            "184/184 [==============================] - 31s 167ms/step - loss: 0.5056 - accuracy: 0.7626 - val_loss: 0.5090 - val_accuracy: 0.7658\n",
            "Epoch 3/10\n",
            "184/184 [==============================] - 36s 194ms/step - loss: 0.4910 - accuracy: 0.7699 - val_loss: 0.5241 - val_accuracy: 0.7418\n",
            "Epoch 4/10\n",
            "184/184 [==============================] - 35s 193ms/step - loss: 0.4889 - accuracy: 0.7710 - val_loss: 0.5055 - val_accuracy: 0.7527\n",
            "Epoch 5/10\n",
            "184/184 [==============================] - 30s 165ms/step - loss: 0.4905 - accuracy: 0.7675 - val_loss: 0.4991 - val_accuracy: 0.7756\n",
            "Epoch 6/10\n",
            "184/184 [==============================] - 30s 163ms/step - loss: 0.4810 - accuracy: 0.7724 - val_loss: 0.4993 - val_accuracy: 0.7734\n",
            "Epoch 7/10\n",
            "184/184 [==============================] - 30s 166ms/step - loss: 0.4779 - accuracy: 0.7811 - val_loss: 0.4695 - val_accuracy: 0.7963\n",
            "Epoch 8/10\n",
            "184/184 [==============================] - 35s 192ms/step - loss: 0.4737 - accuracy: 0.7827 - val_loss: 0.5201 - val_accuracy: 0.7462\n",
            "Epoch 9/10\n",
            "184/184 [==============================] - 30s 163ms/step - loss: 0.4735 - accuracy: 0.7852 - val_loss: 0.4907 - val_accuracy: 0.7832\n",
            "Epoch 10/10\n",
            "184/184 [==============================] - 30s 162ms/step - loss: 0.4734 - accuracy: 0.7843 - val_loss: 0.5018 - val_accuracy: 0.7647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(history.history['val_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkGa5ox2n-b9",
        "outputId": "8330bc8e-9047-4de0-a3b7-aa38a9fd2a99"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.502519503235817"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(history.history['val_accuracy'][5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8VsSKfDodQL",
        "outputId": "825929cf-a040-4136-ec84-5765a25a39e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7727668881416321"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}